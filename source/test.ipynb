{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oPtnzoGe822N"},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"moc3SHp-k2Ip"},"outputs":[],"source":["import logging\n","import pandas as pd\n","import wandb\n","import joblib\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Login to Weights & Biases\n","!wandb login --relogin"],"metadata":{"id":"JnISmVYgyDna"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nh8AgArRwDyI"},"source":["##1.3 Test evaluation"]},{"cell_type":"markdown","metadata":{"id":"ejdJosLcwJtK"},"source":["###1.3.1 Definition of the base classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBZ3IMiY9aD9"},"outputs":[],"source":["class FeatureSelector(BaseEstimator, TransformerMixin):\n","    # Class Constructor\n","    def __init__(self, feature_names):\n","        self.feature_names = feature_names\n","\n","    # Return self nothing else to do here\n","    def fit(self, X, y=None):\n","        return self\n","\n","    # Method that describes what this custom transformer need to do\n","    def transform(self, X, y=None):\n","        return X[self.feature_names]\n","        \n","\n","# transform numerical features\n","class NumericalTransformer(BaseEstimator, TransformerMixin):\n","    # Class constructor method that takes a model parameter as its argument\n","    # model 0: minmax\n","    # model 1: standard\n","    # model 2: without scaler\n","    def __init__(self, model=0, colnames=None):\n","        self.model = model\n","        self.colnames = colnames\n","        self.scaler = None\n","\n","    # Fit is used only to learn statistical about Scalers\n","    def fit(self, X, y=None):\n","        df = pd.DataFrame(X, columns=self.colnames)\n","        # minmax\n","        if self.model == 0:\n","            self.scaler = MinMaxScaler()\n","            self.scaler.fit(df)\n","        # standard scaler\n","        elif self.model == 1:\n","            self.scaler = StandardScaler()\n","            self.scaler.fit(df)\n","        return self\n","\n","    # return columns names after transformation\n","    def get_feature_names_out(self):\n","        return self.colnames\n","\n","    # Transformer method we wrote for this transformer\n","    # Use fitted scalers\n","    def transform(self, X, y=None):\n","        df = pd.DataFrame(X, columns=self.colnames)\n","\n","        # chage values = 0 from some columns\n","        i = 0\n","        for col in df.keys():\n","            if col != 'Pregnancies':\n","                a = df[col]\n","                a = a[a != 0]\n","                a_mean = round(a.median())\n","                print(col,a_mean)\n","                df[col].replace(0,a_mean,inplace=True)\n","                a_mean = 0\n","        \n","        # update columns name\n","        \n","        \n","        self.colnames = df.columns.tolist()\n","        aaa = df.copy()\n","        # minmax\n","        if self.model == 0:\n","            # transform data\n","            df = self.scaler.transform(df)\n","        elif self.model == 1:\n","            # transform data\n","            df = self.scaler.transform(df)\n","        else:\n","            df = df.values\n","            \n","        #df = pd.DataFrame(df, columns=self.colnames)\n","\n","        return df\n","\n","# transform float features\n","class FloatTransformer(BaseEstimator, TransformerMixin):\n","    # Class constructor method that takes a model parameter as its argument\n","    # model 0: minmax\n","    # model 1: standard\n","    # model 2: without scaler\n","    def __init__(self, model=0, colnames=None):\n","        self.model = model\n","        self.colnames = colnames\n","        self.scaler = None\n","\n","    # Fit is used only to learn statistical about Scalers\n","    def fit(self, X, y=None):\n","        df = pd.DataFrame(X, columns=self.colnames)\n","        # minmax\n","        if self.model == 0:\n","            self.scaler = MinMaxScaler()\n","            self.scaler.fit(df)\n","        # standard scaler\n","        elif self.model == 1:\n","            self.scaler = StandardScaler()\n","            self.scaler.fit(df)\n","        return self\n","\n","    # return columns names after transformation\n","    def get_feature_names_out(self):\n","        return self.colnames\n","\n","    # Transformer method we wrote for this transformer\n","    # Use fitted scalers\n","    def transform(self, X, y=None):\n","        df = pd.DataFrame(X, columns=self.colnames)\n","\n","        # chage values = 0 from some columns\n","        for col in df.keys():\n","            a = df[col]\n","            a = a[a != 0]\n","            a_mean = round(a.median(),1)\n","            df[col].replace(0,a_mean,inplace=True)\n","\n","        # update columns name\n","        self.colnames = df.columns.tolist()\n","        aaa = df.copy()\n","        if self.model == 0:\n","            # transform data\n","            df = self.scaler.transform(df)\n","        elif self.model == 1:\n","            # transform data\n","            df = self.scaler.transform(df)\n","        else:\n","            df = df.values\n","\n","        return df\n"]},{"cell_type":"markdown","source":["###1.3.2 Evaluation"],"metadata":{"id":"OYb5sjmtyUwR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KO5Webex9bDY"},"outputs":[],"source":["# global variables\n","\n","# name of the artifact related to test dataset\n","artifact_test_name = \"diabetes_nn/test.csv:latest\"\n","\n","# name of the model artifact\n","artifact_model_name = \"diabetes_nn/model_export:latest\"\n","\n","# name of the target encoder artifact\n","artifact_encoder_name = \"diabetes_nn/target_encoder:latest\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFlDhOKF9gk_"},"outputs":[],"source":["# configure logging\n","logging.basicConfig(level=logging.INFO,\n","                    format=\"%(asctime)s %(message)s\",\n","                    datefmt='%d-%m-%Y %H:%M:%S')\n","\n","# reference for a logging obj\n","logger = logging.getLogger()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpAAKYkx-FQc"},"outputs":[],"source":["# initiate the wandb project\n","run = wandb.init(project=\"diabetes_nn\",job_type=\"test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IW6vFqc9-Alf"},"outputs":[],"source":["logger.info(\"Downloading and reading test artifact\")\n","test_data_path = run.use_artifact(artifact_test_name).file()\n","df_test = pd.read_csv(test_data_path)\n","\n","# Extract the target from the features\n","logger.info(\"Extracting target from dataframe\")\n","x_test = df_test.copy()\n","y_test = x_test.pop(\"Outcome\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"myGovX8h-GdM"},"outputs":[],"source":["# Takes a look at test set\n","x_test.head()"]},{"cell_type":"code","source":["# Take a look at the target variable\n","y_test.head()"],"metadata":{"id":"ArJiI-mnygvi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract the encoding of the target variable\n","logger.info(\"Extracting the encoding of the target variable\")\n","encoder_export_path = run.use_artifact(artifact_encoder_name).file()\n","le = joblib.load(encoder_export_path)"],"metadata":{"id":"pcZzShCcyi2e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform y_train\n","y_test = le.transform(y_test)\n","logger.info(\"Classes [0, 1]: {}\".format(le.inverse_transform([0, 1])))"],"metadata":{"id":"PpES2wBnyis6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target variable after the encoding\n","y_test"],"metadata":{"id":"UWVJOVkayiqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download inference artifact\n","logger.info(\"Downloading and load the exported model\")\n","model_export_path = run.use_artifact(artifact_model_name).file()\n","pipe = joblib.load(model_export_path)"],"metadata":{"id":"fd87F16Byin6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np"],"metadata":{"id":"kBldEHaBMMJS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_model = wandb.restore('model-best.h5', run_path=\"mgoldbarg/diabetes_nn/n6z9gey2\")\n","model = tf.keras.models.load_model(best_model.name)"],"metadata":{"id":"VYcRC-SgL_Lc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler"],"metadata":{"id":"DaxV8lGWOJhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict\n","logger.info(\"Infering\")\n","test_x = pipe.fit_transform(x_test)\n","#predict = model.predict(test_x)\n","p = model.predict(test_x)\n","predict = np.round_(p, decimals=0, out=None)\n","\n","\n","# Evaluation Metrics\n","logger.info(\"Test Evaluation metrics\")\n","fbeta = fbeta_score(y_test, predict, beta=1, zero_division=1)\n","precision = precision_score(y_test, predict, zero_division=1)\n","recall = recall_score(y_test, predict, zero_division=1)\n","acc = accuracy_score(y_test, predict)\n","\n","logger.info(\"Test Accuracy: {}\".format(acc))\n","logger.info(\"Test Precision: {}\".format(precision))\n","logger.info(\"Test Recall: {}\".format(recall))\n","logger.info(\"Test F1: {}\".format(fbeta))\n","\n","run.summary[\"Acc\"] = acc\n","run.summary[\"Precision\"] = precision\n","run.summary[\"Recall\"] = recall\n","run.summary[\"F1\"] = fbeta"],"metadata":{"id":"5Pr_Ci_Cyiih"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_test"],"metadata":{"id":"nR8CLBNBOi0h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predict = model.predict(test_x)\n","p = model.predict(test_x)\n","predict = np.round_(p, decimals=0, out=None)\n","\n","\n","# Evaluation Metrics\n","logger.info(\"Test Evaluation metrics\")\n","fbeta = fbeta_score(y_test, predict, beta=1, zero_division=1)\n","precision = precision_score(y_test, predict, zero_division=1)\n","recall = recall_score(y_test, predict, zero_division=1)\n","acc = accuracy_score(y_test, predict)\n","\n","logger.info(\"Test Accuracy: {}\".format(acc))\n","logger.info(\"Test Precision: {}\".format(precision))\n","logger.info(\"Test Recall: {}\".format(recall))\n","logger.info(\"Test F1: {}\".format(fbeta))\n","\n","run.summary[\"Acc\"] = acc\n","run.summary[\"Precision\"] = precision\n","run.summary[\"Recall\"] = recall\n","run.summary[\"F1\"] = fbeta\n"],"metadata":{"id":"eIavonqDOQ0Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compare the accuracy, precision, recall with previous ones\n","print(classification_report(y_test,predict))"],"metadata":{"id":"P1OyQwc9yia6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig_confusion_matrix, ax = plt.subplots(1,1,figsize=(7,4))\n","ConfusionMatrixDisplay(confusion_matrix(predict,y_test,labels=[1,0]),\n","                       display_labels=[1,0]).plot(values_format=\".0f\",ax=ax)\n","\n","ax.set_xlabel(\"True Label\")\n","ax.set_ylabel(\"Predicted Label\")\n","plt.show()"],"metadata":{"id":"2_3Cmodcysxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Uploading figures\n","logger.info(\"Uploading figures\")\n","run.log(\n","    {\n","        \"confusion_matrix\": wandb.Image(fig_confusion_matrix),\n","        # \"other_figure\": wandb.Image(other_fig)\n","    }\n",")"],"metadata":{"id":"xSRwMpyFysu4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"2R6qLdJ4yssB"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"test.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}